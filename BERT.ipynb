{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfer Learning with BERT - Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T13:43:07.755050Z",
     "start_time": "2020-07-26T13:42:57.174696Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "MKKHGKADQ1Fg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import glob\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bs4 import BeautifulSoup\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLHEfKX2UPVe"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T13:43:53.509417Z",
     "start_time": "2020-07-26T13:43:52.790417Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "TpZBdjNQQ1Fk"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('.\\processed_data\\processed_data.csv',index_col='Unnamed: 0')\n",
    "labels = pd.read_csv('.\\processed_data\\processed_labels.csv',index_col='Unnamed: 0')\n",
    "\n",
    "data = data.rename(columns={\"0\": 'reviews'})\n",
    "labels = labels.rename(columns={\"0\": 'sentiment'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T12:53:37.598119Z",
     "start_time": "2020-07-16T12:53:37.586116Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dDQNJiYwQ1Fn"
   },
   "outputs": [],
   "source": [
    "labels =np.array([1 if x =='positive' else 0 for x in labels['sentiment'].values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T14:08:40.225094Z",
     "start_time": "2020-08-02T14:08:40.220094Z"
    }
   },
   "source": [
    "**Define custom dataset and data loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T10:46:51.490985Z",
     "start_time": "2020-07-16T10:46:50.898936Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "GjnHyDPGQ1Fr"
   },
   "outputs": [],
   "source": [
    "pre_trained_model = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(pre_trained_model)\n",
    "class BertTorchDataset(Dataset):\n",
    "    def __init__(self,data,labels,tokenizer,max_len):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        review = str(self.data[idx])\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(review,\n",
    "                                              add_special_tokens=True,\n",
    "                                              truncation=True,\n",
    "                                              max_length = self.max_len,\n",
    "                                              return_token_type_ids=False,\n",
    "                                              pad_to_max_length=True,\n",
    "                                              return_attention_mask=True,\n",
    "                                              return_tensors='pt'\n",
    "                                              \n",
    "                                             )\n",
    "        \n",
    "        return{\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-16T10:46:51.515148Z",
     "start_time": "2020-07-16T10:46:51.492999Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-Kfr_AbpQ1Fu"
   },
   "outputs": [],
   "source": [
    "def prepare_data_loader(data,labels, tokenizer, max_len=250, batch_size=30):\n",
    "    dataset = BertTorchDataset(\n",
    "        data=np.squeeze(np.array(data)),\n",
    "        labels=np.array(labels),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    \n",
    "    return DataLoader(dataset,batch_size=batch_size)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,labels,test_size=0.2)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test,y_test,test_size=0.4)\n",
    "train_loader = prepare_data_loader(X_train,y_train, tokenizer, max_len=250, batch_size=30)\n",
    "test_loader = prepare_data_loader(X_test, y_test, tokenizer,max_len=250, batch_size=30)\n",
    "val_loader = prepare_data_loader(X_val, y_val, tokenizer,max_len=250, batch_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define BERT model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BB920pfLQ1Fx"
   },
   "outputs": [],
   "source": [
    "class BertSentimentClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(BertSentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(pre_trained_model)\n",
    "        self.drop = nn.Dropout(p=0.1)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(\n",
    "          input_ids=input_ids,\n",
    "          attention_mask=attention_mask\n",
    "        )\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-jAunXMQ1Fz"
   },
   "outputs": [],
   "source": [
    "model = BertSentimentClassifier(n_classes=2)\n",
    "model = model.to(device)\n",
    "n_epochs = 5\n",
    "total_steps = len(train_loader) * n_epochs\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0,num_training_steps=total_steps)\n",
    "criterion= nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define train, evaluation, and test functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-DOesmqHQ1F5"
   },
   "outputs": [],
   "source": [
    "def train_model(model,optimizer,criterion,scheduler,train_loader):\n",
    "    model = model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        input_ids = data['input_ids']\n",
    "        attention_mask = data['attention_mask']\n",
    "        targets = data['label']\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids=input_ids,attention_mask=attention_mask).to(device)\n",
    "        loss = criterion(outputs,targets).to(device)\n",
    "        _, pred = torch.max(outputs, dim=1)\n",
    "        acc = torch.sum(pred == targets)\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss/len(train_loader), epoch_acc/len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQGr0e-dQ1F7"
   },
   "outputs": [],
   "source": [
    "def evaluation_model(model,optimizer,criterion,val_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            input_ids = data['input_ids']\n",
    "            attention_mask = data['attention_mask']\n",
    "            targets = data['label']\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids,attention_mask=attention_mask).to(device)\n",
    "            _, pred = torch.max(outputs, dim=1)\n",
    "            acc = torch.sum(pred == targets)\n",
    "\n",
    "            loss = criterion(outputs,targets).to(device)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return  epoch_loss/len(val_loader), epoch_acc/len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEHL4TFtI3p_"
   },
   "outputs": [],
   "source": [
    "def test_model(model,optimizer,criterion,test_loader):\n",
    "    the_model.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            input_ids = data['input_ids']\n",
    "            attention_mask = data['attention_mask']\n",
    "            targets = data['label']\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids,attention_mask=attention_mask).to(device)\n",
    "            _, pred = torch.max(outputs, dim=1)\n",
    "            acc = torch.sum(pred == targets)\n",
    "\n",
    "            loss = criterion(outputs,targets).to(device)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    return  epoch_loss/len(test_loader), epoch_acc/len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Wx0zZzoCQ1F9",
    "outputId": "431a0769-c690-41cb-e843-fa0910b6d8ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.132 Train Acc: 95.56% Val Loss: 0.248 Val Acc: 91.92%\n",
      "Epoch: 2 Train Loss: 0.073 Train Acc: 98.07% Val Loss: 0.330 Val Acc: 91.97%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    train_loss, train_acc = train_model(model,optimizer,criterion,scheduler,train_loader)\n",
    "    val_loss, val_acc = evaluation_model(model,optimizer,criterion,val_loader)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1} Train Loss: {train_loss:.3f} Train Acc: {train_acc*100:.2f}% Val Loss: {val_loss:.3f} Val Acc: {val_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save trained parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dt6i0vCmFg9K"
   },
   "outputs": [],
   "source": [
    "PATH = \"trained_BERT.pt\"\n",
    "torch.save(model.state_dict(),PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upload trained parameters and to test the model performance on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sqlWGNxkGLZP",
    "outputId": "a5c861c4-9325-4299-af95-28967d7bb442"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_model = BertSentimentClassifier(n_classes=2)\n",
    "the_model.load_state_dict(torch.load(\"trained_BERT.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A_UqazYyI84e",
    "outputId": "ba9011a9-dd21-46e5-80d3-9ca3a496087b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.329 Test Acc: 91.90%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = test_model(model,optimizer,criterion,test_loader)\n",
    "print(f'Test Loss: {test_loss:.3f} Test Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
